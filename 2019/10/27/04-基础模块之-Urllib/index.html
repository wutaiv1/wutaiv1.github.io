<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><link rel="stylesheet" type="text/css" href="//fonts.loli.net/css?family=Source+Code+Pro"><link rel="stylesheet" type="text/css" href="/css/style.css?v=2.0.4"><link rel="stylesheet" type="text/css" href="/css/highlight.css?v=2.0.4"><link rel="Shortcut Icon" href="/favicon.ico"><link rel="bookmark" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><title>04 基础模块之 Urllib | 吴泰的博客</title></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">04 基础模块之 Urllib</h1><a id="logo" href="/.">吴泰的博客</a><p class="description">学海无涯,不进则退</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div><div id="search-form"><div id="result-mask" class="hide"></div><label><input id="search-key" type="text" autocomplete="off" placeholder="搜索"></label><div id="result-wrap" class="hide"><div id="search-result"></div></div><div class="hide"><template id="search-tpl"><div class="item"><a href="/{path}" title="{title}"><div class="title">{title}</div><div class="time">{date}</div><div class="tags">{tags}</div></a></div></template></div></div></div><div id="layout" class="layout-g"><div class="layout-l"><div class="content_container"><div class="post"><h1 class="post-title">04 基础模块之 Urllib</h1><div class="post-meta"><a href="/2019/10/27/04-基础模块之-Urllib/#comments" class="comment-count"></a><p><span class="date">Oct 27, 2019</span><span><a href="/categories/爬虫/" class="category">爬虫</a></span><span><i id="busuanzi_container_page_pv"><i id="busuanzi_value_page_pv"></i><i>点击</i></i></span></p></div><div class="post-content"><p>简介: Urllib 的使用</p>
<a id="more"></a>


<h2 id="4-1-介绍"><a href="#4-1-介绍" class="headerlink" title="4.1 介绍"></a>4.1 介绍</h2><p>Urllib库是python内置HTTP请求库，不需要额外安装即可使用。</p>
<p>相比而言，Request库更加好用(基于Urllib库来实现的)，但是作为一个基本库，了解用法和原理。</p>
<h3 id="4-1-1-包含4个模块"><a href="#4-1-1-包含4个模块" class="headerlink" title="4.1.1 包含4个模块"></a>4.1.1 包含4个模块</h3><p>包含4个模块</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">urllib.request          请求模块</span><br><span class="line">urllib.error            异常处理模块   捕捉异常并进行处理，让程序不会终止</span><br><span class="line">urllib.parse            url 解析模块   比如拆分、解析、合并等等的方法。</span><br><span class="line">urllib.rebotparser      robots.txt解析模块   然后判断哪些网站可以爬，哪些网站不可以爬的，其实用的比较少。</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">robots.txt是一个纯文本文件，在这个文件中网站管理者可以声明该网站中不想被搜索引擎访问的部分，或者指定搜索引擎只收录指定的内容。</span><br><span class="line"></span><br><span class="line">当一个搜索引擎（又称搜索机器人或蜘蛛程序）访问一个站点时，它会首先检查该站点根目录下是否存在robots.txt，</span><br><span class="line">如果存在，搜索机器人就会按照该文件中的内容来确定访问的范围；</span><br><span class="line">如果该文件不存在，那么搜索机器人就沿着链接抓取。</span><br></pre></td></tr></table></figure>

<h3 id="4-1-2-与Python2的变化"><a href="#4-1-2-与Python2的变化" class="headerlink" title="4.1.2 与Python2的变化"></a>4.1.2 与Python2的变化</h3><p>python2</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib2   </span><br><span class="line"><span class="comment">#urlopen 在python3中移动到request模块中</span></span><br><span class="line">response = urllib2.urlopen(<span class="string">'http://www.baidu.com'</span>)</span><br></pre></td></tr></table></figure>

<p>python3</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line">response = urllib.request.urlopen(<span class="string">'http://www.baidu.com'</span>)</span><br></pre></td></tr></table></figure>

<h2 id="4-2-Request-请求处理模块"><a href="#4-2-Request-请求处理模块" class="headerlink" title="4.2 Request 请求处理模块"></a>4.2 Request 请求处理模块</h2><h3 id="4-2-1-urlopen"><a href="#4-2-1-urlopen" class="headerlink" title="4.2.1 urlopen"></a>4.2.1 urlopen</h3><p>打开URL URL，它可以是字符串或Request对象</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">urllib.request.urlopen(url, data=<span class="literal">None</span>, [timeout,]*, cafile=<span class="literal">None</span>, capath=<span class="literal">None</span>, cadefault=<span class="literal">False</span>, context=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>

<p>url: 网站的url<br>data：额外是数据，例如post数据。必须是指定要发送到的其他数据的对象服务器，如果不需要此类数据，则为“无”。<br>timeout ：可选的* timeout <em>参数指定以秒为单位的超时，阻止连接尝试之类的操作（如果未指定，则将使用全局默认超时设置）。这仅适用于HTTP，HTTPS和FTP连接。<br>cafile和capath : 可选的 *cafile</em> 和 <em>capath</em> 参数指定一组受信任的CA HTTPS请求的证书。</p>
<h4 id="Get请求"><a href="#Get请求" class="headerlink" title="Get请求"></a>Get请求</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">response = urllib.request.urlopen(<span class="string">'http://www.baidu.com'</span>)   <span class="comment"># get请求一个网页</span></span><br><span class="line">print(response.read().decode(<span class="string">'utf-8'</span>))</span><br></pre></td></tr></table></figure>

<h4 id="Post请求"><a href="#Post请求" class="headerlink" title="Post请求"></a>Post请求</h4><p>如果要以POST发送一个请求，只需要把参数data以bytes形式传入。不加data,是get方式传送。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">data = &#123;   <span class="comment"># 传入的数据是一个字典数据</span></span><br><span class="line">    <span class="string">'word'</span>: <span class="string">'hello'</span></span><br><span class="line">&#125;</span><br><span class="line">query_string = bytes(urllib.parse.urlencode(data),encoding=<span class="string">'utf8'</span>) <span class="comment"># 注意 encoding是传入bytes的参数非urlencode参数</span></span><br><span class="line">response = urllib.request.urlopen(<span class="string">'http://httpbin.org/post'</span>,data=query_string)</span><br><span class="line">print(response.read())</span><br></pre></td></tr></table></figure>

<p>返回结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">b'&#123;\n  "args": &#123;&#125;, \n  "data": "", \n  "files": &#123;&#125;, \n  "form": &#123;\n    "word": "hello"\n  &#125;, \n  "headers": &#123;\n    "Accept-Encoding": "identity", \n    "Content-Length": "10", \n    "Content-Type": "application/x-www-form-urlencoded", \n    "Host": "httpbin.org", \n    "User-Agent": "Python-urllib/3.7"\n  &#125;, \n  "json": null, \n  "origin": "111.196.243.150, 111.196.243.150", \n  "url": "https://httpbin.org/post"\n&#125;\n'</span></span><br></pre></td></tr></table></figure>

<h4 id="设置超时"><a href="#设置超时" class="headerlink" title="设置超时"></a>设置超时</h4><p>定以秒为单位的超时阻止连接尝试之类的操作（如果未指定，则将使用全局默认超时设置）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.error</span><br><span class="line"></span><br><span class="line">response1 = urllib.request.urlopen(<span class="string">'http://httpbin.org/get'</span>, timeout=<span class="number">1</span>) <span class="comment"># Get 请求，1s内请求，请求成功返回请求数据</span></span><br><span class="line">print(response1.read())</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = urllib.request.urlopen(<span class="string">'http://httpbin.org/get'</span>,timeout=<span class="number">0.1</span>)  <span class="comment">#  0.1s， 请求会超时，会抛出异常</span></span><br><span class="line"><span class="keyword">except</span> urllib.error.URLError <span class="keyword">as</span> e :  <span class="comment"># 捕捉异常，</span></span><br><span class="line">    <span class="keyword">if</span> isinstance(e.reason,socket.timeout):   <span class="comment"># 这里reason中返回的是socket.timeout 类型对象。</span></span><br><span class="line">        print(<span class="string">"TIME OUT"</span>)</span><br></pre></td></tr></table></figure>

<p>结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">b&apos;&#123;\n  &quot;args&quot;: &#123;&#125;, \n  &quot;headers&quot;: &#123;\n    &quot;Accept-Encoding&quot;: &quot;identity&quot;, \n    &quot;Host&quot;: &quot;httpbin.org&quot;, \n    &quot;User-Agent&quot;: &quot;Python-urllib/3.7&quot;\n  &#125;, \n  &quot;origin&quot;: &quot;111.196.243.150, 111.196.243.150&quot;, \n  &quot;url&quot;: &quot;https://httpbin.org/get&quot;\n&#125;\n&apos;</span><br><span class="line">TIME OUT</span><br></pre></td></tr></table></figure>

<p>补充:  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">URLError是urllib.error模块的一个类，当使用request产生异常时都可以通过捕获这个类来处理。</span><br><span class="line">它具有一个属性reason，返回错误的原因。</span><br><span class="line">另外，它还有一个子类是HTTPError，专门处理 HTTP 请求错误。它有如下 3 个属性：</span><br><span class="line"> 1）code： 返回 HTTP 状态码，比如 404 表示网页不存在， 500 表示服务器内部错误等。</span><br><span class="line"> 2）reason：同父类一样，用于返回错误的原因。 </span><br><span class="line"> 3）headers： 返回请求头。</span><br><span class="line"></span><br><span class="line">URLError 中有很多类型的异常，而 socket.timeout 只是其中一种，所以用 isinstance(e.reason, socket.timeout) 来判断，对超时这种异常单独处理</span><br><span class="line"></span><br><span class="line">isinstance(object, classinfo)  # 判读对象是否属于一个类型，是则返回True, 例如 isinstance (1 ,int) 返回true</span><br></pre></td></tr></table></figure>

<h3 id="4-2-2-Response-响应信息"><a href="#4-2-2-Response-响应信息" class="headerlink" title="4.2.2 Response 响应信息"></a>4.2.2 Response 响应信息</h3><h4 id="响应类型、状态码、响应头"><a href="#响应类型、状态码、响应头" class="headerlink" title="响应类型、状态码、响应头"></a>响应类型、状态码、响应头</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">response = urllib.request.urlopen(<span class="string">'http://www.python.org'</span>)</span><br><span class="line">print(type(response)) <span class="comment"># Response 的类型是http.client.HTTPResponse</span></span><br><span class="line">print(response.status) <span class="comment"># 获取状态码</span></span><br><span class="line">print(response.getheaders())  <span class="comment"># 查看响应头，集合内包含数组类型</span></span><br><span class="line">print(response.getheader(<span class="string">'Server'</span>))  <span class="comment"># 具体的响应头内容，使用的方法是getheader，所有用的0是getheaders</span></span><br></pre></td></tr></table></figure>

<p>结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;class &apos;http.client.HTTPResponse&apos;&gt;</span><br><span class="line">200</span><br><span class="line">[(&apos;Server&apos;, &apos;nginx&apos;), (&apos;Content-Type&apos;, &apos;text/html; charset=utf-8&apos;), (&apos;X-Frame-Options&apos;, &apos;DENY&apos;), (&apos;Via&apos;, &apos;1.1 vegur&apos;), (&apos;Via&apos;, &apos;1.1 varnish&apos;), (&apos;Content-Length&apos;, &apos;48699&apos;), (&apos;Accept-Ranges&apos;, &apos;bytes&apos;), (&apos;Date&apos;, &apos;Thu, 17 Oct 2019 16:26:43 GMT&apos;), (&apos;Via&apos;, &apos;1.1 varnish&apos;), (&apos;Age&apos;, &apos;1038&apos;), (&apos;Connection&apos;, &apos;close&apos;), (&apos;X-Served-By&apos;, &apos;cache-iad2129-IAD, cache-hnd18743-HND&apos;), (&apos;X-Cache&apos;, &apos;HIT, HIT&apos;), (&apos;X-Cache-Hits&apos;, &apos;1, 1594&apos;), (&apos;X-Timer&apos;, &apos;S1571329603.476597,VS0,VE0&apos;), (&apos;Vary&apos;, &apos;Cookie&apos;), (&apos;Strict-Transport-Security&apos;, &apos;max-age=63072000; includeSubDomains&apos;)]</span><br><span class="line">nginx</span><br></pre></td></tr></table></figure>

<p>显示网页的所有内容</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line">response = urllib.request.urlopen(<span class="string">'http://www.python.org'</span>)</span><br><span class="line"></span><br><span class="line">print(response.read().decode(<span class="string">'utf-8'</span>))</span><br></pre></td></tr></table></figure>

<h3 id="4-2-3-Request"><a href="#4-2-3-Request" class="headerlink" title="4.2.3 Request"></a>4.2.3 Request</h3><p>我们知道利用urlopen( )方法可以实现最基本请求的发起，但这几个简单的参数并不足以构建一个完整的请求。如果请求中需要加入Headers等信息，就可以利用更强大的Request类来构建。</p>
<p>例子1：获取页面</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">request = urllib.request.Request(<span class="string">'https://python.org'</span>)  <span class="comment"># 是&lt;class 'urllib.request.Request'&gt; ， </span></span><br><span class="line"></span><br><span class="line">response = urllib.request.urlopen(request)  <span class="comment"># 将Request 对象 传给urlopen, 请求网页，与上面的请求效果相同</span></span><br><span class="line">print(response.read().decode(<span class="string">'utf-8'</span>))</span><br></pre></td></tr></table></figure>

<p>例子2:设置请求头数据进行访问</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request,parse</span><br><span class="line">url_v = <span class="string">'http://httpbin.org/post'</span></span><br><span class="line">headers_v = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'</span>,</span><br><span class="line">    <span class="string">'Host'</span>:<span class="string">'httpbin.org'</span></span><br><span class="line">&#125;</span><br><span class="line">dict_value = &#123;</span><br><span class="line">    <span class="string">'name'</span>:<span class="string">'Germey'</span></span><br><span class="line">&#125;</span><br><span class="line">data_v = bytes(parse.urlencode(dict_value),encoding=<span class="string">'utf8'</span>)  <span class="comment"># 生成post 请求数据</span></span><br><span class="line">req = request.Request(url=url_v,data=data_v,headers=headers_v,method=<span class="string">'POST'</span>) <span class="comment"># Request 使用自定义的请求头进行访问</span></span><br><span class="line">response = request.urlopen(req)</span><br><span class="line">print(response.read().decode(<span class="string">'utf-8'</span>))</span><br></pre></td></tr></table></figure>

<p>结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;args&quot;: &#123;&#125;, </span><br><span class="line">  &quot;data&quot;: &quot;&quot;, </span><br><span class="line">  &quot;files&quot;: &#123;&#125;, </span><br><span class="line">  &quot;form&quot;: &#123;</span><br><span class="line">    &quot;name&quot;: &quot;Germey&quot;</span><br><span class="line">  &#125;, </span><br><span class="line">  &quot;headers&quot;: &#123;</span><br><span class="line">    &quot;Accept-Encoding&quot;: &quot;identity&quot;, </span><br><span class="line">    &quot;Content-Length&quot;: &quot;11&quot;, </span><br><span class="line">    &quot;Content-Type&quot;: &quot;application/x-www-form-urlencoded&quot;, </span><br><span class="line">    &quot;Host&quot;: &quot;httpbin.org&quot;, </span><br><span class="line">    &quot;User-Agent&quot;: &quot;Python-urllib/3.7,Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)&quot;</span><br><span class="line">  &#125;, </span><br><span class="line">  &quot;json&quot;: null, </span><br><span class="line">  &quot;origin&quot;: &quot;111.196.243.150, 111.196.243.150&quot;, </span><br><span class="line">  &quot;url&quot;: &quot;https://httpbin.org/post&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>另外headers的一些属性，下面的需要特别注意一下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">User-Agent : 有些服务器或 Proxy 会通过该值来判断是否是浏览器发出的请求</span><br><span class="line">Content-Type : 在使用 REST 接口时，服务器会检查该值，用来确定 HTTP Body 中的内容该怎样解析。</span><br><span class="line">application/xml ： 在 XML RPC，如 RESTful/SOAP 调用时使用</span><br><span class="line">application/json ： 在 JSON RPC 调用时使用</span><br><span class="line">application/x-www-form-urlencoded ： 浏览器提交 Web 表单时使用</span><br><span class="line">在使用服务器提供的 RESTful 或 SOAP 服务时， Content-Type 设置错误会导致服务器拒绝服务</span><br></pre></td></tr></table></figure>

<h3 id="4-2-4-Handler代理"><a href="#4-2-4-Handler代理" class="headerlink" title="4.2.4 Handler代理"></a>4.2.4 Handler代理</h3><ul>
<li><p>什么是代理：代理就是第三方代替本体处理相关事务。例如：生活中的代理：代购，中介，微商……</p>
</li>
<li><p>爬虫中为什么需要使用代理？  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">一些网站会有相应的反爬虫措施，例如很多网站会检测某一段时间某个IP的访问次数，如果访问频率太快以至于看起来不像正常访客，它可能就会会禁止这个IP的访问。</span><br><span class="line">所以我们需要设置一些代理IP，每隔一段时间换一个代理IP，就算IP被禁止，依然可以换个IP继续爬取。</span><br></pre></td></tr></table></figure>
</li>
<li><p>代理的分类：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">　正向代理：代理客户端获取数据。正向代理是为了保护客户端防止被追究责任。</span><br><span class="line">　反向代理：代理服务器提供数据。反向代理是为了保护服务器或负责负载均衡。</span><br></pre></td></tr></table></figure>

</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"></span><br><span class="line"><span class="comment">#1.创建处理器对象，在其内部封装代理ip和端口</span></span><br><span class="line">handler=urllib.request.ProxyHandler(proxies=&#123;<span class="string">'http'</span>:<span class="string">'95.172.58.224:52608'</span>&#125;)</span><br><span class="line"><span class="comment">#2.创建opener对象，然后使用该对象发起一个请求</span></span><br><span class="line">opener=urllib.request.build_opener(handler)</span><br><span class="line"></span><br><span class="line">url=<span class="string">'http://www.baidu.com/s?ie=UTF-8&amp;wd=ip'</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">request = urllib.request.Request(url, headers=headers)</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用opener对象发起请求，该请求对应的ip即为我们设置的代理ip</span></span><br><span class="line">response = opener.open(request)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'./daili.html'</span>,<span class="string">'wb'</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    fp.write(response.read())</span><br></pre></td></tr></table></figure>

<h3 id="4-2-6-Cookie"><a href="#4-2-6-Cookie" class="headerlink" title="4.2.6 Cookie"></a>4.2.6 Cookie</h3><ul>
<li><p>cookie概念</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">当用户通过浏览器首次访问一个域名时，访问的web服务器会给客户端发送数据，以保持web服务器与客户端之间的状态保持，这些数据就是cookie。</span><br></pre></td></tr></table></figure>
</li>
<li><p>cookie作用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">我们在浏览器中，经常涉及到数据的交换，比如你登录邮箱，登录一个页面。我们经常会在此时设置30天内记住我，或者自动登录选项。</span><br><span class="line">那么它们是怎么记录信息的呢，答案就是今天的主角cookie了，Cookie是由HTTP服务器设置的，保存在浏览器中，但HTTP协议是一种无状态协议，</span><br><span class="line">在数据交换完毕后，服务器端和客户端的链接就会关闭，每次交换数据都需要建立新的链接。</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>例子1：读取网页，获取cookie 数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> http.cookiejar,urllib.request</span><br><span class="line"></span><br><span class="line"><span class="comment"># 闯将cookiejar对象</span></span><br><span class="line">cookle_v = http.cookiejar.CookieJar()</span><br><span class="line"><span class="comment"># 创建处理器对象(携带cookiejar对象的)</span></span><br><span class="line">handler_v = urllib.request.HTTPCookieProcessor(cookle_v)</span><br><span class="line"><span class="comment"># 创建一个opener 对象，传入handle</span></span><br><span class="line">opener =urllib.request.build_opener(handler_v)</span><br><span class="line"><span class="comment"># 使用opener.open打开百度网页，cookie会自动赋值,cookle_v 中自动存入百度cookie数据</span></span><br><span class="line">response = opener.open(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> cookle_v:</span><br><span class="line">    print(item.name+<span class="string">"="</span>+item.value)</span><br></pre></td></tr></table></figure>

<p>结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">BAIDUID=796A3014C5B8B3D6522BA0479D83A132:FG=1</span><br><span class="line">BIDUPSID=796A3014C5B8B3D6522BA0479D83A132</span><br><span class="line">H_PS_PSSID=1427_21097_18560_29568_29220_29911</span><br><span class="line">PSTM=1571347700</span><br><span class="line">delPer=0</span><br><span class="line">BDSVRTM=0</span><br><span class="line">BD_HOME=0</span><br></pre></td></tr></table></figure>

<p>例子2：将cookie的数据保存到本地</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> http.cookiejar,urllib.request</span><br><span class="line"></span><br><span class="line">filename= <span class="string">'Cookie.txt'</span></span><br><span class="line"><span class="comment"># 生成cookiejar的子类对象</span></span><br><span class="line">cookie_v = http.cookiejar.MozillaCookieJar(filename)</span><br><span class="line">handler_v = urllib.request.HTTPCookieProcessor(cookie_v)</span><br><span class="line">opener =urllib.request.build_opener(handler_v)</span><br><span class="line">response = opener.open(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line"><span class="comment">#使用save方法</span></span><br><span class="line">cookie_v.save(ignore_discard=<span class="literal">True</span>,ignore_expires=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>本地创建Cookie.txt ，内容如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># Netscape HTTP Cookie File</span><br><span class="line"># http://curl.haxx.se/rfc/cookie_spec.html</span><br><span class="line"># This is a generated file!  Do not edit.</span><br><span class="line"></span><br><span class="line">.baidu.com	TRUE	/	FALSE	3718832329	BAIDUID	A3096B19FD83945F9C7D59240C098881:FG=1</span><br><span class="line">.baidu.com	TRUE	/	FALSE	3718832329	BIDUPSID	A3096B19FD83945F9C7D59240C098881</span><br><span class="line">.baidu.com	TRUE	/	FALSE		H_PS_PSSID	1443_21113_29568_29220_26350_29910</span><br><span class="line">.baidu.com	TRUE	/	FALSE	3718832329	PSTM	1571348681</span><br><span class="line">.baidu.com	TRUE	/	FALSE		delPer	0</span><br><span class="line">www.baidu.com	FALSE	/	FALSE		BDSVRTM	0</span><br><span class="line">www.baidu.com	FALSE	/	FALSE		BD_HOME	0</span><br></pre></td></tr></table></figure>


<p>保存方式2：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import http.cookiejar,urllib.request</span><br><span class="line"></span><br><span class="line">filename= &apos;Cookie.txt&apos;</span><br><span class="line">cookie_v = http.cookiejar.LWPCookieJar(filename) # 使用类不同</span><br><span class="line">handler_v = urllib.request.HTTPCookieProcessor(cookie_v)</span><br><span class="line">opener =urllib.request.build_opener(handler_v)</span><br><span class="line">response = opener.open(&apos;http://www.baidu.com&apos;)</span><br><span class="line">cookie_v.save(ignore_discard=True,ignore_expires=True)</span><br></pre></td></tr></table></figure>

<p>结果，格式与上面的不同</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#LWP-Cookies-2.0</span><br><span class="line">Set-Cookie3: BAIDUID=&quot;2B2C53DE6F9F35482D6A3DCB7FD52B35:FG=1&quot;; path=&quot;/&quot;; domain=&quot;.baidu.com&quot;; path_spec; domain_dot; expires=&quot;2020-10-16 21:53:43Z&quot;; comment=bd; version=0</span><br><span class="line">Set-Cookie3: BIDUPSID=2B2C53DE6F9F35486E1E82B0F21C8A56; path=&quot;/&quot;; domain=&quot;.baidu.com&quot;; path_spec; domain_dot; expires=&quot;2087-11-05 01:07:50Z&quot;; version=0</span><br><span class="line">Set-Cookie3: H_PS_PSSID=1423_21082_29567_29699_29220; path=&quot;/&quot;; domain=&quot;.baidu.com&quot;; path_spec; domain_dot; discard; version=0</span><br><span class="line">Set-Cookie3: PSTM=1571349222; path=&quot;/&quot;; domain=&quot;.baidu.com&quot;; path_spec; domain_dot; expires=&quot;2087-11-05 01:07:50Z&quot;; version=0</span><br><span class="line">Set-Cookie3: delPer=0; path=&quot;/&quot;; domain=&quot;.baidu.com&quot;; path_spec; domain_dot; discard; version=0</span><br><span class="line">Set-Cookie3: BDSVRTM=0; path=&quot;/&quot;; domain=&quot;www.baidu.com&quot;; path_spec; discard; version=0</span><br><span class="line">Set-Cookie3: BD_HOME=0; path=&quot;/&quot;; domain=&quot;www.baidu.com&quot;; path_spec; discard; version=0</span><br></pre></td></tr></table></figure>

<h2 id="4-3-error模块-异常处理"><a href="#4-3-error模块-异常处理" class="headerlink" title="4.3 error模块 异常处理"></a>4.3 error模块 异常处理</h2><p>官方文档</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://docs.python.org/3/library/urllib.error.html</span><br></pre></td></tr></table></figure>

<p>urllib.error模块为urllib.request引发的异常而定义异常类。<br>基本异常类是URLError。</p>
<ul>
<li><p>urllib.error.URLError : 处理程序遇到问题时会引发此异常（或派生的异常）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reason  出现此错误的原因。它可以是消息字符串或其他异常实例。</span><br></pre></td></tr></table></figure>
</li>
<li><p>urllib.error.HTTPError : 尽管是一个异常（URLError的子类）， HTTPError但也可以用作非异常文件状的返回值（与urlopen()返回的东西相同）。在处理异常的HTTP错误（例如身份验证请求）时，此功能很有用。</p>
</li>
<li><p>urllib.error.ContentTooShortError（msg，content ）:当urlretrieve() 函数检测到下载数据量小于预期量（由Content-Length标头提供）时，将引发此异常。该content属性存储下载的（假定为截断的）数据。</p>
</li>
</ul>
<p>例1: 在不存在的网址下，打印出错误信息，error.URLError</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request,error</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = request.urlopen(<span class="string">'http://cuiqingcal.com/index.html'</span>)  <span class="comment"># 地址不存在</span></span><br><span class="line"><span class="keyword">except</span> error.URLError <span class="keyword">as</span> e:  <span class="comment"># 捕获错误信息 error.URLError</span></span><br><span class="line">    print(e.reason) <span class="comment">#  reason 是错误原因</span></span><br></pre></td></tr></table></figure>

<p>结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[Errno 11001] getaddrinfo failed    # 获取地址失败</span><br></pre></td></tr></table></figure>

<p>例2：打印请求失败响应头信息</p>
<p>注意:HTTPError 是URLErros 的子类，所以放在其前面，当HTTPError捕捉不到时，才使用父类进行捕捉</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request, error</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = request.urlopen(<span class="string">'https://www.bilibili.com/inddex.html'</span>)</span><br><span class="line"><span class="keyword">except</span> error.HTTPError <span class="keyword">as</span> e:</span><br><span class="line">    print(e.reason, e.code, e.headers, sep=<span class="string">'\n'</span>)</span><br><span class="line"><span class="keyword">except</span> error.URLError <span class="keyword">as</span> e:</span><br><span class="line">    print(e.reason)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    print(<span class="string">'Request Successfully'</span>)</span><br></pre></td></tr></table></figure>

<p>结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Not Found</span><br><span class="line">404  # 显示网页不存在</span><br><span class="line">Date: Thu, 17 Oct 2019 23:26:46 GMT</span><br><span class="line">Content-Type: text/html</span><br><span class="line">Transfer-Encoding: chunked</span><br><span class="line">Connection: close</span><br><span class="line">Server: Tengine</span><br><span class="line">Content-Encoding: gzip</span><br></pre></td></tr></table></figure>

<p>例3: 超时异常的捕捉</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.error</span><br><span class="line"></span><br><span class="line">response1 = urllib.request.urlopen(<span class="string">'http://httpbin.org/get'</span>, timeout=<span class="number">1</span>) <span class="comment"># Get 请求，1s内请求，请求成功返回请求数据</span></span><br><span class="line">print(response1.read())</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = urllib.request.urlopen(<span class="string">'http://httpbin.org/get'</span>,timeout=<span class="number">0.1</span>)  <span class="comment">#  0.1s， 请求会超时，会抛出异常</span></span><br><span class="line"><span class="keyword">except</span> urllib.error.URLError <span class="keyword">as</span> e :  <span class="comment"># 捕捉异常，</span></span><br><span class="line">    <span class="keyword">if</span> isinstance(e.reason,socket.timeout):   <span class="comment"># 这里reason中返回的是socket.timeout 类型对象。</span></span><br><span class="line">        print(<span class="string">"TIME OUT"</span>)</span><br></pre></td></tr></table></figure>

<h2 id="4-4-Parse-URL解析模块"><a href="#4-4-Parse-URL解析模块" class="headerlink" title="4.4 Parse URL解析模块"></a>4.4 Parse URL解析模块</h2><h3 id="4-4-1-urlpase"><a href="#4-4-1-urlpase" class="headerlink" title="4.4.1 urlpase"></a>4.4.1 urlpase</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">urllib.parse.urlparse(url, scheme=<span class="string">''</span>, allow_fragments=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">URL分割成6部分    &lt;scheme&gt;://&lt;netloc&gt;/&lt;path&gt;;&lt;params&gt;?&lt;query&gt;#&lt;fragment&gt;</span><br><span class="line">返回一个 6个元素的元组: (scheme, netloc, path, params, query, fragment).</span><br></pre></td></tr></table></figure>

<p>例1： 默认将URL分为6部分</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlparse</span><br><span class="line"></span><br><span class="line">result = urlparse(<span class="string">'http://www.baidu.com/index.html;user?id=4#comment'</span>)</span><br><span class="line">print(type(result),result,sep=<span class="string">"\n"</span>)</span><br></pre></td></tr></table></figure>

<p>结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;class &apos;urllib.parse.ParseResult&apos;&gt;  # 显示类型</span><br><span class="line">ParseResult(scheme=&apos;http&apos;, netloc=&apos;www.baidu.com&apos;, path=&apos;/index.html&apos;, params=&apos;user&apos;, query=&apos;id=4&apos;, fragment=&apos;comment&apos;) # 路径，get请求数据，将URL划分为6部分</span><br></pre></td></tr></table></figure>

<p>例2: 无http协议时，指定协议</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">result = urlparse(&apos;www.baidu.com/index.html;user?id=4#comment&apos;,scheme=&apos;https&apos;)  # 无http 协议，指定为https协议，如果有协议，指定的http 协议不生效</span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure>

<p>结果:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ParseResult(scheme=&apos;https&apos;, netloc=&apos;&apos;, path=&apos;www.baidu.com/index.html&apos;, params=&apos;user&apos;, query=&apos;id=4&apos;, fragment=&apos;comment&apos;)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result = urlparse(&apos;http://www.baidu.com/index.html;user?id=4#comment&apos;,scheme=&apos;https&apos;)  # 如果有协议，指定的https协议不生效</span><br></pre></td></tr></table></figure>

<p>例3: allow_fragments</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># comment 是一个锚点，allow_fragments=False后，将comment 拼接到前面去</span><br><span class="line">result = urlparse(&apos;www.baidu.com/index.html;user?id=4#comment&apos;,allow_fragments=False)</span><br><span class="line">print(result)</span><br><span class="line"></span><br><span class="line">result2 = urlparse(&apos;www.baidu.com/index.html#comment&apos;,allow_fragments=False)</span><br><span class="line">print(result2)</span><br></pre></td></tr></table></figure>

<p>结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 有查询参数comment拼接到查询上去</span><br><span class="line">ParseResult(scheme=&apos;&apos;, netloc=&apos;&apos;, path=&apos;www.baidu.com/index.html&apos;, params=&apos;user&apos;, query=&apos;id=4#comment&apos;, fragment=&apos;&apos;) </span><br><span class="line"># 无查询参数comment拼接到html路径上去</span><br><span class="line">ParseResult(scheme=&apos;&apos;, netloc=&apos;&apos;, path=&apos;www.baidu.com/index.html#comment&apos;, params=&apos;&apos;, query=&apos;&apos;, fragment=&apos;&apos;)</span><br></pre></td></tr></table></figure>

<h3 id="4-4-2-urlparse"><a href="#4-4-2-urlparse" class="headerlink" title="4.4.2 urlparse"></a>4.4.2 urlparse</h3><p>与urlpase的相反函数，将6个参数拼接为一个URL</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlunparse</span><br><span class="line">data = [<span class="string">'http'</span>,<span class="string">'www.baidu.com'</span>,<span class="string">'index.html'</span>,<span class="string">'user'</span>,<span class="string">'a=6'</span>,<span class="string">'comment'</span>]</span><br><span class="line">print(urlunparse(data))</span><br></pre></td></tr></table></figure>

<p>结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://www.baidu.com/index.html;user?a=6#comment</span><br></pre></td></tr></table></figure>

<h3 id="4-4-3-urljoin"><a href="#4-4-3-urljoin" class="headerlink" title="4.4.3 urljoin"></a>4.4.3 urljoin</h3><p>拼接2个地址，一般是url +path</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urljoin</span><br><span class="line">url=<span class="string">'http://ip/</span></span><br><span class="line"><span class="string">path='</span>api/user/login<span class="string">'</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">urljoin(url,path)拼接后的路径为'</span>http//ip/api/user/login<span class="string">'</span></span><br></pre></td></tr></table></figure>

<h3 id="4-4-4-urllencode"><a href="#4-4-4-urllencode" class="headerlink" title="4.4.4 urllencode"></a>4.4.4 urllencode</h3><p>将字典或由两个元素组成的元组序列编码为URL查询字符串</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlencode</span><br><span class="line"></span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">'name'</span>: <span class="string">'germey'</span>,</span><br><span class="line">    <span class="string">'age'</span>: <span class="number">22</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">base_url = <span class="string">'http://www.baidu.com?'</span></span><br><span class="line">url = base_url + urlencode(params)</span><br><span class="line">print(url)</span><br></pre></td></tr></table></figure>

<p>结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://www.baidu.com?name=germey&amp;age=22</span><br></pre></td></tr></table></figure>

</div><div class="post-copyright"><blockquote><p>原文作者: 吴泰</p><p>原文链接: <a href="http://yoursite.com/2019/10/27/04-基础模块之-Urllib/">http://yoursite.com/2019/10/27/04-基础模块之-Urllib/</a></p><p>版权声明: 转载请注明出处(必须保留原文作者署名原文链接)</p></blockquote></div><div class="tags"><a href="/tags/爬虫/">爬虫</a></div><div class="post-share"><div class="social-share"><span>分享到:</span></div></div><div class="post-nav"><a href="/2019/10/27/05-基础模块之Request模块和Response响应/" class="pre">05 基础模块之Request模块和Response响应</a><a href="/2019/10/27/05-hexo-其他/" class="next">05 hexo 好用的插件</a></div><div id="comments"></div></div></div></div><div class="layout-r"><div id="sidebar"><div class="search-pla"></div><div id="toc" class="widget"><div class="widget-title"><i class="fa fa-fei">文章目录</i></div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#4-1-介绍"><span class="toc-text">4.1 介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-1-包含4个模块"><span class="toc-text">4.1.1 包含4个模块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-2-与Python2的变化"><span class="toc-text">4.1.2 与Python2的变化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-2-Request-请求处理模块"><span class="toc-text">4.2 Request 请求处理模块</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-1-urlopen"><span class="toc-text">4.2.1 urlopen</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Get请求"><span class="toc-text">Get请求</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Post请求"><span class="toc-text">Post请求</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#设置超时"><span class="toc-text">设置超时</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-2-Response-响应信息"><span class="toc-text">4.2.2 Response 响应信息</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#响应类型、状态码、响应头"><span class="toc-text">响应类型、状态码、响应头</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-3-Request"><span class="toc-text">4.2.3 Request</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-4-Handler代理"><span class="toc-text">4.2.4 Handler代理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-6-Cookie"><span class="toc-text">4.2.6 Cookie</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-3-error模块-异常处理"><span class="toc-text">4.3 error模块 异常处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-4-Parse-URL解析模块"><span class="toc-text">4.4 Parse URL解析模块</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-1-urlpase"><span class="toc-text">4.4.1 urlpase</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-2-urlparse"><span class="toc-text">4.4.2 urlparse</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-3-urljoin"><span class="toc-text">4.4.3 urljoin</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-4-urllencode"><span class="toc-text">4.4.4 urllencode</span></a></li></ol></li></ol></div><div class="widget"><div class="widget-title"><i class="fa fa-xie"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/10/27/11-正则解析html/">11 正则解析html</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/27/13-Scrapy-爬取知乎用户信息/">13 Scrapy 爬取知乎用户信息</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/27/12-scrapy-框架基础知识/"> 12 scrapy 框架基础知识</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/27/实战1-Requests-正则表达式抓取猫眼TOP100/">10 实战1 Requests+正则表达式抓取猫眼TOP100</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/27/09-selinux-模块/">09  selinux 模块</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/27/08 解析模块之Xpath 模块/">08 解析模块之Xpath 模块</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/27/07 PyQuery  模块的使用/">07 PyQuery  模块的使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/27/06 BeautifulSoup 模块的使用/">06 BeautifulSoup 模块的使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/27/05-基础模块之Request模块和Response响应/">05 基础模块之Request模块和Response响应</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/27/04-基础模块之-Urllib/">04 基础模块之 Urllib</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-gui"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Hexo/">Hexo</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/爬虫/">爬虫</a><span class="category-list-count">13</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-biao"> 标签</i></div><div class="tagcloud"><a href="/tags/Anaconda/" style="font-size: 15px;">Anaconda</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/爬虫/" style="font-size: 15px;">爬虫</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-archive"> 归档</i></div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">十月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">八月 2019</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-you"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div></div><a id="totop" href="#top"></a><div id="footer"><div class="footer-info"><p><a href="/baidusitemap.xml">网站地图</a> |  <a href="/atom.xml">订阅本站</a> |  <a href="/about/">联系博主</a></p><p>本站总访问量：<i id="busuanzi_container_site_pv"><i id="busuanzi_value_site_pv"></i></i>次，本站总访客数:<i id="busuanzi_container_site_uv"><i id="busuanzi_value_site_uv"></i></i>人</p><p><span> Copyright &copy;<a href="/." rel="nofollow">吴泰.</a></span><span> Theme by<a rel="nofollow" target="_blank" href="https://github.com/chaooo/hexo-theme-BlueLake"> BlueLake.</a></span><span> Count by<a href="http://busuanzi.ibruce.info/"> busuanzi.</a></span><span> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a></span></p></div></div></div><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script type="text/javascript" src="/js/search.json.js?v=2.0.4"></script><script type="text/javascript" id="maid-script" src="https://unpkg.com/mermaid@7.1.2/dist/mermaid.min.js?v=2.0.4"></script><script>if (window.mermaid) {
  var options = JSON.parse(document.getElementById('maid-script').getAttribute('mermaidoptioins'));
  mermaid.initialize(options);
}</script><script type="text/javascript" src="/js/toctotop.js?v=2.0.4" async></script><link rel="stylesheet" type="text/css" href="/share/css/share.css"><script type="text/javascript" src="/share/js/social-share.js" charset="utf-8"></script><script type="text/javascript" src="/share/js/qrcode.js" charset="utf-8"></script></body></html>